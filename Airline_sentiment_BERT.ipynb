{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Airline-sentiment-BERT.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53410d0a48f047ee8e666a2e817c2e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d81fc87d8e24c77b1db56147ad0d4c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc56b45a31804d119425d1670d4f9e71",
              "IPY_MODEL_3d5ff5b2a2d440888c957dd3d4ea4a30",
              "IPY_MODEL_7fa3447b74ce45c39cc237a0999f9ae9"
            ]
          }
        },
        "2d81fc87d8e24c77b1db56147ad0d4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc56b45a31804d119425d1670d4f9e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03fd1b07de014fe48a335898f3f98bf9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d3c7997a65d4944a421f73a1923f780"
          }
        },
        "3d5ff5b2a2d440888c957dd3d4ea4a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45d57338c8984780b7daf089e64bf9f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7aa94f227bb04a59af77e0646bd68126"
          }
        },
        "7fa3447b74ce45c39cc237a0999f9ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94b972a25d7c4c1886b3d4add278a9c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 511M/511M [00:47&lt;00:00, 11.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a86500c49f3648aeae6e0ed55f1ce6c2"
          }
        },
        "03fd1b07de014fe48a335898f3f98bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d3c7997a65d4944a421f73a1923f780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45d57338c8984780b7daf089e64bf9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7aa94f227bb04a59af77e0646bd68126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94b972a25d7c4c1886b3d4add278a9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a86500c49f3648aeae6e0ed55f1ce6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:46:52.775909Z",
          "iopub.execute_input": "2022-01-07T05:46:52.776175Z",
          "iopub.status.idle": "2022-01-07T05:47:14.186346Z",
          "shell.execute_reply.started": "2022-01-07T05:46:52.776147Z",
          "shell.execute_reply": "2022-01-07T05:47:14.185514Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKvh8N677V-z",
        "outputId": "0192b322-a71c-4285-d2c7-591cb9eaf27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 185 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=d2bd88d83580b0646d33834ec380c51e5ce400dc1ac14293a755cc5e2d42d4b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=012311514f2b21e1280faf04318e9b36932c60f1b8cbc38c23db6b76b302ee70\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=81f9c90fd001cd97c95244c9f20386247ff315d894c48466ab60b6a96f3d79b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxiC93uw8UOr",
        "outputId": "efd46c64-30b8-419b-d234-07512ef42e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model,Sequential, Input, load_model\n",
        "from keras.layers import *\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "#from transformers import TFBertModel, BertTokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from itertools import combinations as comb\n",
        "import ntpath\n",
        "import glob\n",
        "import math\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "#from transformers import TFBertModel, DistilBertTokenizerFast\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:28.178065Z",
          "iopub.execute_input": "2022-01-07T05:47:28.178341Z",
          "iopub.status.idle": "2022-01-07T05:47:33.255867Z",
          "shell.execute_reply.started": "2022-01-07T05:47:28.178309Z",
          "shell.execute_reply": "2022-01-07T05:47:33.255119Z"
        },
        "trusted": true,
        "id": "UT6bpSy77V-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BukpjIco7eXm",
        "outputId": "15bf915f-8cb5-4aca-da9e-fd8d9959c9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP2iol3_7gWW",
        "outputId": "0f96a564-c3d5-4d9c-a335-751ebf30c163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('./Tweets.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:37.453069Z",
          "iopub.execute_input": "2022-01-07T05:47:37.453776Z",
          "iopub.status.idle": "2022-01-07T05:47:37.577971Z",
          "shell.execute_reply.started": "2022-01-07T05:47:37.453737Z",
          "shell.execute_reply": "2022-01-07T05:47:37.57723Z"
        },
        "trusted": true,
        "id": "XUf1hM4d7V-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY2PYqL0Qa1z",
        "outputId": "9539495f-d937-4111-d34f-35bcf580332d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive=df[df['airline_sentiment']=='positive'].text\n",
        "neutral=df[df['airline_sentiment']=='neutral'].text\n",
        "negative=df[df['airline_sentiment']=='negative'].text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:39.872789Z",
          "iopub.execute_input": "2022-01-07T05:47:39.87348Z",
          "iopub.status.idle": "2022-01-07T05:47:39.894063Z",
          "shell.execute_reply.started": "2022-01-07T05:47:39.873441Z",
          "shell.execute_reply": "2022-01-07T05:47:39.893368Z"
        },
        "trusted": true,
        "id": "Ez4dV5jc7V-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Sentiments to 0,1,2\n",
        "def convert_Sentiment(sentiment):\n",
        "    if  sentiment == \"positive\":\n",
        "        return 2\n",
        "    elif sentiment == \"neutral\":\n",
        "        return 1\n",
        "    elif sentiment == \"negative\":\n",
        "        return 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:41.168549Z",
          "iopub.execute_input": "2022-01-07T05:47:41.169371Z",
          "iopub.status.idle": "2022-01-07T05:47:41.173327Z",
          "shell.execute_reply.started": "2022-01-07T05:47:41.169333Z",
          "shell.execute_reply": "2022-01-07T05:47:41.1726Z"
        },
        "trusted": true,
        "id": "bDrtmMKQ7V-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply convert_Sentiment function\n",
        "df.airline_sentiment = df.airline_sentiment.apply(lambda x : convert_Sentiment(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:46.102018Z",
          "iopub.execute_input": "2022-01-07T05:47:46.102495Z",
          "iopub.status.idle": "2022-01-07T05:47:46.118715Z",
          "shell.execute_reply.started": "2022-01-07T05:47:46.102455Z",
          "shell.execute_reply": "2022-01-07T05:47:46.118048Z"
        },
        "trusted": true,
        "id": "GHrYYzhO7V-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11fK9NuG8EJQ",
        "outputId": "06dbd7fc-d774-42a8-cf40-eb5e8ab41769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "def remove_stopwords(text):\n",
        "    text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])\n",
        "    return text\n",
        "\n",
        "# Remove url  \n",
        "def remove_url(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "# Remove punct\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "# Remove html \n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "# Remove @username\n",
        "def remove_username(text):\n",
        "    return re.sub('@[^\\s]+','',text)\n",
        "\n",
        "# Remove emojis\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "# Decontraction text\n",
        "def decontraction(text):\n",
        "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
        "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
        "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
        "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
        "    \n",
        "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
        "    text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
        "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
        "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
        "    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
        "    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
        "    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
        "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    return text  \n",
        "\n",
        "# Seperate alphanumeric\n",
        "def seperate_alphanumeric(text):\n",
        "    words = text\n",
        "    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n",
        "    return \" \".join(words)\n",
        "\n",
        "def cont_rep_char(text):\n",
        "    tchr = text.group(0) \n",
        "    \n",
        "    if len(tchr) > 1:\n",
        "        return tchr[0:2] \n",
        "\n",
        "def unique_char(rep, text):\n",
        "    substitute = re.sub(r'(\\w)\\1+', rep, text)\n",
        "    return substitute\n",
        "\n",
        "def char(text):\n",
        "    substitute = re.sub(r'[^a-zA-Z]',' ',text)\n",
        "    return substitute\n",
        "\n",
        "# combaine negative reason with  tweet (if exsist)\n",
        "df['final_text'] = df['negativereason'].fillna('') + ' ' + df['text'] \n",
        "\n",
        "\n",
        "# Apply functions on tweets\n",
        "df['final_text'] = df['final_text'].apply(lambda x : remove_username(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : remove_url(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : remove_emoji(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : decontraction(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : seperate_alphanumeric(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : unique_char(cont_rep_char,x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : char(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : x.lower())\n",
        "df['final_text'] = df['final_text'].apply(lambda x : remove_stopwords(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:47:49.314815Z",
          "iopub.execute_input": "2022-01-07T05:47:49.31525Z",
          "iopub.status.idle": "2022-01-07T05:48:19.094603Z",
          "shell.execute_reply.started": "2022-01-07T05:47:49.315216Z",
          "shell.execute_reply": "2022-01-07T05:48:19.09389Z"
        },
        "trusted": true,
        "id": "YPggm-mJ7V-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['final_text']\n",
        "y = df['airline_sentiment']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:48:24.904858Z",
          "iopub.execute_input": "2022-01-07T05:48:24.905449Z",
          "iopub.status.idle": "2022-01-07T05:48:24.909371Z",
          "shell.execute_reply.started": "2022-01-07T05:48:24.905411Z",
          "shell.execute_reply": "2022-01-07T05:48:24.908546Z"
        },
        "trusted": true,
        "id": "POvpcHSD7V-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import bert\n",
        "import transformers\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:48:27.586246Z",
          "iopub.execute_input": "2022-01-07T05:48:27.586961Z",
          "iopub.status.idle": "2022-01-07T05:48:29.403417Z",
          "shell.execute_reply.started": "2022-01-07T05:48:27.586916Z",
          "shell.execute_reply": "2022-01-07T05:48:29.402699Z"
        },
        "trusted": true,
        "id": "XaVgrRZy7V-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\", trainable=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:48:32.475267Z",
          "iopub.execute_input": "2022-01-07T05:48:32.475522Z",
          "iopub.status.idle": "2022-01-07T05:49:04.398631Z",
          "shell.execute_reply.started": "2022-01-07T05:48:32.475492Z",
          "shell.execute_reply": "2022-01-07T05:49:04.397898Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6df00j0S7V-8",
        "outputId": "4739d6dc-96f5-482e-88f9-c36830836ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1, Total size: 1.26GB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "\n",
        "def encoder(sentences):\n",
        "  ids = []\n",
        "  for sentence in sentences:\n",
        "    encoding = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    max_length=16,\n",
        "    truncation = True,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=False,\n",
        "    pad_to_max_length=True,\n",
        "    return_attention_mask=False)\n",
        "    ids.append(encoding['input_ids'])\n",
        "  return ids\n",
        "\n",
        "#Train test split\n",
        "train_sents,test_sents, train_labels, test_labels  = train_test_split(X,y,test_size=0.15)\n",
        "\n",
        "train_ids = encoder(train_sents)\n",
        "test_ids = encoder(test_sents) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:49:31.368371Z",
          "iopub.execute_input": "2022-01-07T05:49:31.368638Z",
          "iopub.status.idle": "2022-01-07T05:49:31.375236Z",
          "shell.execute_reply.started": "2022-01-07T05:49:31.368606Z",
          "shell.execute_reply": "2022-01-07T05:49:31.374572Z"
        },
        "trusted": true,
        "id": "1OlleCcG7V-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5eca87-51af-4a54-d59d-054aa6f45c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = tf.convert_to_tensor(train_ids)\n",
        "test_ids = tf.convert_to_tensor(test_ids)\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "train_labels = tf.convert_to_tensor(train_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:50:03.024035Z",
          "iopub.execute_input": "2022-01-07T05:50:03.024287Z",
          "iopub.status.idle": "2022-01-07T05:50:07.782239Z",
          "shell.execute_reply.started": "2022-01-07T05:50:03.024257Z",
          "shell.execute_reply": "2022-01-07T05:50:07.781176Z"
        },
        "trusted": true,
        "id": "KDPafxRt7V--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=50\n",
        "bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "input_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")  \n",
        "embedding = bert_encoder([input_word_ids])\n",
        "dense = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(embedding[0])\n",
        "dense = tf.keras.layers.Dense(128, activation='relu',kernel_regularizer='l2')(dense)\n",
        "dense = tf.keras.layers.Dropout(0.2)(dense)   \n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid',kernel_regularizer='l2')(dense)    \n",
        "\n",
        "model = tf.keras.Model(inputs=[input_word_ids], outputs=output)  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T05:50:27.872357Z",
          "iopub.execute_input": "2022-01-07T05:50:27.873064Z",
          "iopub.status.idle": "2022-01-07T05:50:28.989995Z",
          "shell.execute_reply.started": "2022-01-07T05:50:27.873021Z",
          "shell.execute_reply": "2022-01-07T05:50:28.989276Z"
        },
        "trusted": true,
        "id": "hEZ_dnq_7V-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "53410d0a48f047ee8e666a2e817c2e83",
            "2d81fc87d8e24c77b1db56147ad0d4c6",
            "dc56b45a31804d119425d1670d4f9e71",
            "3d5ff5b2a2d440888c957dd3d4ea4a30",
            "7fa3447b74ce45c39cc237a0999f9ae9",
            "03fd1b07de014fe48a335898f3f98bf9",
            "8d3c7997a65d4944a421f73a1923f780",
            "45d57338c8984780b7daf089e64bf9f6",
            "7aa94f227bb04a59af77e0646bd68126",
            "94b972a25d7c4c1886b3d4add278a9c8",
            "a86500c49f3648aeae6e0ed55f1ce6c2"
          ]
        },
        "outputId": "5f5af901-1b7f-4684-9c8c-afbe79f284a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53410d0a48f047ee8e666a2e817c2e83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sBERT = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "# sBERT.compile(SGD(lr=learning_rate, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.compile(Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "train_history = model.fit(x = train_ids, y = train_labels, epochs = 3, verbose = 1, batch_size = 32, validation_data = (test_ids, test_labels))\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:09:19.714779Z",
          "iopub.execute_input": "2022-01-07T06:09:19.715324Z",
          "iopub.status.idle": "2022-01-07T06:14:24.467348Z",
          "shell.execute_reply.started": "2022-01-07T06:09:19.715285Z",
          "shell.execute_reply": "2022-01-07T06:14:24.466565Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TkoCA-O7V-_",
        "outputId": "2058a401-4130-4198-b151-e209719b8e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389/389 [==============================] - 72s 147ms/step - loss: -7.5087 - accuracy: 0.7862 - val_loss: -22.0358 - val_accuracy: 0.8174\n",
            "Epoch 2/3\n",
            "389/389 [==============================] - 56s 145ms/step - loss: -3.3612 - accuracy: 0.4144 - val_loss: 2.5716 - val_accuracy: 0.1926\n",
            "Epoch 3/3\n",
            "389/389 [==============================] - 56s 144ms/step - loss: 2.3321 - accuracy: 0.2693 - val_loss: 2.1153 - val_accuracy: 0.1926\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer)  [(None, 16)]             0         \n",
            "                                                                 \n",
            " tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  109482240\n",
            "                             lingAndCrossAttentions(l            \n",
            "                             ast_hidden_state=(None,             \n",
            "                             16, 768),                           \n",
            "                              pooler_output=(None, 76            \n",
            "                             8),                                 \n",
            "                              past_key_values=None, h            \n",
            "                             idden_states=None, atten            \n",
            "                             tions=None, cross_attent            \n",
            "                             ions=None)                          \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 768)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               98432     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,580,801\n",
            "Trainable params: 109,580,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = sBERT.predict(val_input)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:16:18.970141Z",
          "iopub.execute_input": "2022-01-07T06:16:18.970848Z",
          "iopub.status.idle": "2022-01-07T06:16:41.879816Z",
          "shell.execute_reply.started": "2022-01-07T06:16:18.970808Z",
          "shell.execute_reply": "2022-01-07T06:16:41.879058Z"
        },
        "trusted": true,
        "id": "oNNW69Ns7V-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" accuracy_score: {}\".format(accuracy_score(val_labels,test_pred.round())))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:19:28.80038Z",
          "iopub.execute_input": "2022-01-07T06:19:28.800923Z",
          "iopub.status.idle": "2022-01-07T06:19:28.80705Z",
          "shell.execute_reply.started": "2022-01-07T06:19:28.80088Z",
          "shell.execute_reply": "2022-01-07T06:19:28.806337Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNhOfhoB7V-_",
        "outputId": "c746c8f6-c95b-49ed-f311-971a1d447efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy_score: 0.19808743169398907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_encoder = Model(input_word_ids, model.get_layer('lambda').output)\n",
        "bert_encoder.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:15:40.507336Z",
          "iopub.execute_input": "2022-01-07T06:15:40.507594Z",
          "iopub.status.idle": "2022-01-07T06:15:40.531115Z",
          "shell.execute_reply.started": "2022-01-07T06:15:40.507565Z",
          "shell.execute_reply": "2022-01-07T06:15:40.53036Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJqrU9C7V_A",
        "outputId": "4dfde70b-2a65-42a0-fccb-9b1275f62b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer)  [(None, 16)]             0         \n",
            "                                                                 \n",
            " tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  109482240\n",
            "                             lingAndCrossAttentions(l            \n",
            "                             ast_hidden_state=(None,             \n",
            "                             16, 768),                           \n",
            "                              pooler_output=(None, 76            \n",
            "                             8),                                 \n",
            "                              past_key_values=None, h            \n",
            "                             idden_states=None, atten            \n",
            "                             tions=None, cross_attent            \n",
            "                             ions=None)                          \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 768)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,482,240\n",
            "Trainable params: 109,482,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_embed = bert_encoder.predict(train_ids)\n",
        "test_embed = bert_encoder.predict(test_ids)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:21:07.278272Z",
          "iopub.execute_input": "2022-01-07T06:21:07.278567Z",
          "iopub.status.idle": "2022-01-07T06:22:54.680828Z",
          "shell.execute_reply.started": "2022-01-07T06:21:07.278517Z",
          "shell.execute_reply": "2022-01-07T06:22:54.680061Z"
        },
        "trusted": true,
        "id": "4jogzbVY7V_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(train_embed).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nYLXv1yfli9",
        "outputId": "f2c93136-bf3e-4acf-e39c-6cb697a61fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12444, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_imp_space(X_train, Y_train, X_test, imp_feature_size, foz):\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  imp_train_data = X_train.values\n",
        "  imp_test_data = X_test.values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  d = len(X_train.columns)\n",
        "  num_class=len(np.unique(Y_train))\n",
        "  # print(\"____1_____\")\n",
        "  for i in range(0,imp_feature_size*foz):\n",
        "    Xindis = np.random.permutation(d)\n",
        "    for j in range(0,d-(foz-1),foz):  #d/foz kadar doner\n",
        "      sX = np.random.permutation(num_class)\n",
        "      s1 = sX[0]\n",
        "      # print(\"____2_____\")\n",
        "      s1data = X_train[X_train.index.isin(Y_train[Y_train == str(s1)].index)]\n",
        "      s2data = X_train[~X_train.index.isin(Y_train[Y_train == str(s1)].index)]\n",
        "      s1data = s1data.iloc[:,Xindis[j:j+(foz)]]\n",
        "      s2data = s2data.iloc[:,Xindis[j:j+(foz)]] # s1 vs all other classes, #foz feature\n",
        "      # print(\"____3_____\")\n",
        "      s1label = np.ones((s1data.values.shape[0],1),dtype=int)\n",
        "      s2label = -1*np.ones((s2data.values.shape[0],1),dtype=int)\n",
        "      Wdata = np.concatenate((s1data,s2data))\n",
        "      # print(\"____4_____\")\n",
        "      \n",
        "      Wdata = x2fx(Wdata)\n",
        "      Wlabel = np.concatenate((s1label,s2label))\n",
        "      W = np.matmul(np.matmul(np.linalg.pinv(np.matmul(Wdata.T, Wdata)),Wdata.T),Wlabel)\n",
        "      \n",
        "      WW = x2fx(X_train.iloc[:,Xindis[j:j+(foz)]].values)\n",
        "      imp_train_data = np.concatenate((imp_train_data, np.matmul(WW,W)),axis=1)\n",
        "      \n",
        "      TT = x2fx(X_test.iloc[:,Xindis[j:j+(foz)]].values)\n",
        "      imp_test_data = np.concatenate((imp_test_data, np.matmul(TT,W)),axis=1)\n",
        "    \n",
        "  return imp_train_data,imp_test_data\n",
        "  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:23:46.1735Z",
          "iopub.execute_input": "2022-01-07T06:23:46.174184Z",
          "iopub.status.idle": "2022-01-07T06:36:16.342076Z",
          "shell.execute_reply.started": "2022-01-07T06:23:46.174142Z",
          "shell.execute_reply": "2022-01-07T06:36:16.340923Z"
        },
        "trusted": true,
        "id": "aom1DpAI7V_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def x2fx(x, model='quadratic'):\n",
        "    linear = np.c_[np.ones(x.shape[0]), x]\n",
        "    if model == 'linear':\n",
        "        return linear\n",
        "    if model == 'purequadratic':\n",
        "        return np.c_[linear, x**2]\n",
        "    interaction = np.array([x[:,i]*x[:,j] for i, j in comb(range(x.shape[1]), 2)]).T\n",
        "    if model == 'interaction':\n",
        "        return np.c_[linear, interaction]\n",
        "    if model == 'quadratic':\n",
        "        return np.c_[linear, interaction, x**2]\n",
        "def MajorityVoting(votes):\n",
        "  results = []\n",
        "  for i in range(0,votes.shape[1]):\n",
        "    values, counts = np.unique(votes[:,i], return_counts=True)\n",
        "    results.append(values[np.argmax(counts)])\n",
        "  return np.array(results)"
      ],
      "metadata": {
        "id": "Y1GP069_hAco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foz=4\n",
        "imp_feature_size=1\n",
        "acc_imp=[]\n",
        "\n",
        "acc_norm=[]\n",
        "acc_incept=[]\n",
        "imp_tree_predicts=[]\n",
        "tree_predicts=[]\n",
        "train_embed=pd.DataFrame(train_embed)\n",
        "d=len(train_embed.columns)\n",
        "for i in range(0,5):\n",
        "    imp_tr, imp_ts = generate_imp_space(train_embed, train_labels, test_embed, imp_feature_size, foz)\n",
        "    imp_d = imp_tr.shape[1]\n",
        "    imp_sel_d = 2* round(math.log2(imp_d)) #feature\n",
        "    sel_d = 2*round(math.log2(d))\n",
        "      \n",
        "    imp_tree = XGBClassifier(max_depth=imp_sel_d, n_estimators=50,random_state=42)\n",
        "   \n",
        "    imp_tree.fit(imp_tr, train_labels)\n",
        "    imp_tree_predicts.append(imp_tree.predict(imp_ts))\n",
        "\n",
        "\n",
        "    tree = XGBClassifier(max_depth=sel_d, n_estimators=50,random_state=42)\n",
        "    \n",
        "    tree.fit(train_embed, train_labels)\n",
        "    tree_predicts.append(tree.predict(test_embed))\n",
        "result_imp=MajorityVoting(np.array(imp_tree_predicts))\n",
        "result_norm=MajorityVoting(np.array(tree_predicts))\n",
        "acc_imp.append(metrics.accuracy_score(test_labels, result_imp))\n",
        "acc_norm.append(metrics.accuracy_score(test_labels, result_norm))\n",
        "#result_norm=encoder.fit_transform(result_norm)\n",
        "#result_imp=encoder.fit_transform(result_imp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "LX0ku-nFhEmJ",
        "outputId": "25746692-a240-430d-e8c7-e3d1422488dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-e2ed64e06c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtree_predicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mresult_imp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMajorityVoting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp_tree_predicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mresult_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMajorityVoting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_predicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['0  ', '1  ', '2  ', '3  ', '4  ', '5  ', '6  ', '7  ', '8  ', '9  ', '10 ', '11 ', '12 ', '13 ', '14 ', '15 ', '16 ', '17 ', '18 ', '19 ', '20 ', '21 ', '22 ', '23 ', '24 ', '25 ', '26 ', '27 ', '28 ', '29 ', '30 ', '31 ', '32 ', '33 ', '34 ', '35 ', '36 ', '37 ', '38 ', '39 ', '40 ', '41 ', '42 ', '43 ', '44 ', '45 ', '46 ', '47 ', '48 ', '49 ', '50 ', '51 ', '52 ', '53 ', '54 ', '55 ', '56 ', '57 ', '58 ', '59 ', '60 ', '61 ', '62 ', '63 ', '64 ', '65 ', '66 ', '67 ', '68 ', '69 ', '70 ', '71 ', '72 ', '73 ', '74 ', '75 ', '76 ', '77 ', '78 ', '79 ', '80 ', '81 ', '82 ', '83 ', '84 ', '85 ', '86 ', '87 ', '88 ', '89 ', '90 ', '91 ', '92 ', '93 ', '94 ', '95 ', '96 ', '97 ', '98 ', '99 ', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', ...\nexpected 74 , 575, 214, 396, 25 , 152, 521, 210, 587, 218, 642, 548, 467, 245, 582, 685, 553, 349, 366, 373, 686, 452, 221, 158, 298, 603, 78 , 97 , 273, 719, 472, 45 , 699, 147, 495, 367, 399, 556, 14 , 223, 526, 644, 184, 628, 384, 300, 215, 112, 294, 651, 652, 313, 689, 227, 697, 334, 735, 274, 611, 567, 542, 465, 49 , 201, 340, 579, 324, 605, 529, 438, 156, 750, 510, 509, 211, 760, 99 , 764, 291, 232, 149, 400, 573, 303, 468, 516, 607, 103, 178, 371, 470, 42 , 436, 131, 493, 369, 412, 301, 22 , 559, 251, 132, 574, 445, 246, 441, 616, 28 , 269, 674, 591, 395, 515, 758, 739, 679, 744, 496, 695, 118, 335, 341, 715, 1  , 128, 447, 93 , 50 , 141, 413, 75 , 312, 124, 662, 364, 9  , 34 , 466, 292, 172, 555, 659, 423, 670, 704, 428, 81 , 418, 161, 712, 492, 484, 237, 281, 143, 122, 356, 631, 219, 592, 751, 12 , 191, 275, 295, 171, 408, 504, 27 , 684, 746, 675, 374, 145, 13 , 571, 67 , 561, 185, 168, 87 , 208, 439, 121, 609, 134, 560, 129, 60 , 498, 57 , 668, 722, 8  , 742, 84 , 142, 612, 429, 236, 518, 290, 138, 585, 733, 753, 425, 323, 419, 563, 43 , 576, 691, 469, 347, 94 , 336, 15 , 713, 207, 595, 456, 409, 506, 543, 615, 663, 709, 482, 568, 286, 622, 711, 170, 4  , 162, 326, 110, 153, 583, 688, 358, 508, 337, 477, 10 , 33 , 522, 58 , 687, 287, 255, 79 , 443, 318, 680, 588, 256, 435, 604, 451, 406, 702, 23 , 268, 61 , 90 , 381, 272, 296, 362, 705, 69 , 51 , 368, 350, 655, 673, 696, 111, 241, 282, 535, 279, 660, 85 , 653, 68 , 116, 160, 748, 762, 344, 176, 431, 763, 249, 550...\ntraining data did not have the following fields: f119, f651, f539, f170, f726, f426, f281, f179, f554, f405, f442, f202, f398, f3, f164, f530, f33, f464, f736, f662, f83, f507, f226, f701, f486, f629, f206, f66, f93, f324, f407, f252, f263, f80, f22, f471, f105, f248, f369, f590, f466, f415, f514, f552, f115, f531, f24, f18, f262, f311, f563, f727, f178, f86, f334, f480, f683, f195, f301, f321, f259, f449, f482, f750, f95, f434, f34, f50, f36, f181, f628, f331, f354, f300, f463, f655, f216, f17, f447, f307, f718, f163, f171, f166, f173, f607, f679, f149, f100, f577, f666, f739, f441, f177, f744, f351, f603, f400, f652, f751, f48, f40, f502, f433, f371, f593, f298, f527, f462, f282, f515, f565, f289, f720, f168, f451, f151, f747, f653, f63, f89, f399, f489, f501, f566, f508, f542, f754, f136, f336, f4, f511, f49, f159, f267, f473, f346, f663, f556, f503, f766, f352, f543, f731, f528, f187, f620, f599, f94, f513, f183, f123, f81, f618, f338, f545, f65, f109, f560, f378, f84, f749, f656, f25, f296, f685, f497, f689, f104, f64, f143, f381, f261, f594, f246, f339, f353, f291, f32, f342, f523, f746, f444, f668, f457, f348, f74, f161, f287, f472, f318, f385, f361, f6, f340, f308, f193, f8, f370, f431, f285, f357, f158, f374, f735, f649, f633, f325, f134, f120, f255, f706, f47, f335, f59, f203, f635, f210, f389, f613, f383, f729, f453, f43, f591, f589, f525, f209, f227, f639, f292, f765, f175, f128, f394, f532, f709, f320, f425, f189, f686, f260, f570, f257, f728, f759, f553, f199..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_embed=pd.DataFrame(train_embed).values\n",
        "test_embed=pd.DataFrame(test_embed).values\n",
        "tree = XGBClassifier(max_depth=sel_d, n_estimators=50,random_state=42)\n",
        "tree.fit(train_embed,train_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:40:08.490407Z",
          "iopub.execute_input": "2022-01-07T06:40:08.49068Z",
          "iopub.status.idle": "2022-01-07T06:40:08.601951Z",
          "shell.execute_reply.started": "2022-01-07T06:40:08.490632Z",
          "shell.execute_reply": "2022-01-07T06:40:08.601376Z"
        },
        "trusted": true,
        "id": "ECeEIbcX7V_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7330a392-0fcd-4ada-cc89-3019f0ec41a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(max_depth=20, n_estimators=50, objective='multi:softprob',\n",
              "              random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=tree.predict(test_embed)\n",
        "metrics.accuracy_score(test_labels, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d4s-BKu3Jbo",
        "outputId": "6cd178da-c399-4fce-b1da-ec97eeaf2297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8474499089253188"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfclassifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 0)\n",
        "rfclassifier.fit(train_embed, train_labels)\n",
        "test_predrf = rfclassifier.predict(test_embed).round().astype(int)\n",
        "print(\"RF: \", accuracy_score(test_labels, test_predrf))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T06:44:48.360733Z",
          "iopub.execute_input": "2022-01-07T06:44:48.361211Z",
          "iopub.status.idle": "2022-01-07T06:44:56.813781Z",
          "shell.execute_reply.started": "2022-01-07T06:44:48.361172Z",
          "shell.execute_reply": "2022-01-07T06:44:56.81292Z"
        },
        "trusted": true,
        "id": "g8FVOmoZ7V_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a404a1b2-7f80-4a99-b7a1-2800000f6d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF:  0.8146630236794171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc_imp)\n",
        "print(acc_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMF_giiuWvIV",
        "outputId": "dc2f1afa-007c-47cd-e4ea-dced099126ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8169398907103825]\n",
            "[0.8205828779599271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GB\")\n",
        "print(acc_imp)\n",
        "print(acc_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNwI82BJjB6H",
        "outputId": "0eb4353b-75a9-4a0b-e133-65edcbe30106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GB\n",
            "[0.7190346083788707]\n",
            "[0.726775956284153]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_imp=MajorityVoting(np.array(imp_tree_predicts))\n",
        "metrics.accuracy_score(test_labels, result_imp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273rOXZFt7r9",
        "outputId": "9ddc06a0-ca9e-4821-b978-e607b3d38f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8397085610200364"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imp_space_herlev.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGX6-RTEPjva"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "import imutils\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "from sklearn import model_selection\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from itertools import combinations as comb\n",
        "import ntpath\n",
        "import glob\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uU1VaoBPkjz",
        "outputId": "eb1a03ac-416c-43a1-afda-461e8a39a195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JkRErnHQ3Vw",
        "outputId": "c73a9178-4bbd-4238-fb4c-67b205ed3b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDir = \"./smear/smear2005/\"\n",
        "testDir = \"./smear/smear2005/Images/test\"\n",
        "categories=[\"carcinoma_in_situ\",\"light_dysplastic\",\"moderate_dysplastic\",\"normal_columnar\",\"normal_intermediate\",\"normal_superficiel\",\"severe_dysplastic\"]\n",
        "images_folder = \"./smear/smear2005/All_Image/\"\n",
        "labels_folder = \"./smear/smear2005/Imgs/NEW_IM/\"\n",
        "IMG_HEIGHT=256\n",
        "IMG_WIDTH=256\n",
        "IMG_CHANNELS=3"
      ],
      "metadata": {
        "id": "jXRPHZlEPuH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_excel(images_folder+'/'+\"new_database_results.xls\")\n",
        "train=train[['ID','Class']]\n"
      ],
      "metadata": {
        "id": "joY3tKBOPpDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train)):\n",
        "  if train['Class'][i]==1 or train['Class'][i]==2 or train['Class'][i]==3:\n",
        "    train['Class'][i]='0'\n",
        "  #elif train['Class'][i]==4 or train['Class'][i]==5 or train['Class'][i]==6:\n",
        "   #train['Class'][i]='1'\n",
        "  else:\n",
        "    train['Class'][i]='1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ5QJcq4P6iv",
        "outputId": "9b1e787c-c9c3-49d2-aef8-32d1fc6e284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Inceptionv3(class_no):\n",
        "  print(\"-------------------------------------Inceptionv3--------------------------------------------\")\n",
        "  input_shape_densenet = (128, 128, 3)\n",
        "  incept_model = tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\",input_shape=input_shape_densenet)\n",
        "  incept_model.trainable = True\n",
        "  \n",
        "  x = tf.keras.layers.MaxPooling2D()(incept_model.output)\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(512, activation='relu',kernel_regularizer='l2')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  layer = tf.keras.layers.Dense(units=class_no,activation='softmax',kernel_regularizer='l2')(x)\n",
        "  model = tf.keras.models.Model(incept_model.input, outputs=layer)\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  #history = model.fit(train_imgs, train_labels, batch_size=32, epochs=num_epochs,verbose=0)\n",
        "  #X_train_features,X_valid_features=incept_rf(incept_model,model,train_imgs,test_imgs,k)\n",
        "  #result_imp,result_norm=imp_incept_rf(X_train_features,X_valid_features,train_labels)\n",
        "  #print(\"------------------------------------------------------------------------------------------\")\n",
        "  return incept_model, model"
      ],
      "metadata": {
        "id": "ZqmZeBoHPE4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improved Space Part**"
      ],
      "metadata": {
        "id": "P_AdZURYUwdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def incept_rf(base_model,modely,train_imgs,test_imgs,i):\n",
        "  X_train_features = []\n",
        "  X_valid_features = []\n",
        "  if(i==0):\n",
        "\n",
        "    feature_network = Model(base_model.input, modely.get_layer('flatten').output)\n",
        "  else:\n",
        "    feature_network = Model(base_model.input, modely.get_layer('flatten_'+str(i)).output)\n",
        "  X_train_features = feature_network.predict(train_imgs)  # Assuming you have your images in x\n",
        "  X_valid_features = feature_network.predict(test_imgs)\n",
        "  return X_train_features,X_valid_features\n"
      ],
      "metadata": {
        "id": "eNcSEq0URkof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_imp_space(X_train, Y_train, X_test, imp_feature_size, foz):\n",
        "  imp_train_data = X_train.values\n",
        "  imp_test_data = X_test.values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  d = len(X_train.columns)\n",
        "  # print(\"____1_____\")\n",
        "  for i in range(0,imp_feature_size*foz):\n",
        "    Xindis = np.random.permutation(d)\n",
        "    for j in range(0,d-(foz-1),foz):  #d/foz kadar doner\n",
        "      sX = np.random.permutation(num_class)\n",
        "      s1 = sX[0]\n",
        "      # print(\"____2_____\")\n",
        "      s1data = X_train[X_train.index.isin(Y_train[Y_train == str(s1)].index)]\n",
        "      s2data = X_train[~X_train.index.isin(Y_train[Y_train == str(s1)].index)]\n",
        "      s1data = s1data.iloc[:,Xindis[j:j+(foz)]]\n",
        "      s2data = s2data.iloc[:,Xindis[j:j+(foz)]] # s1 vs all other classes, #foz feature\n",
        "      # print(\"____3_____\")\n",
        "      s1label = np.ones((s1data.values.shape[0],1),dtype=int)\n",
        "      s2label = -1*np.ones((s2data.values.shape[0],1),dtype=int)\n",
        "      Wdata = np.concatenate((s1data,s2data))\n",
        "      # print(\"____4_____\")\n",
        "      \n",
        "      Wdata = x2fx(Wdata)\n",
        "      Wlabel = np.concatenate((s1label,s2label))\n",
        "      W = np.matmul(np.matmul(np.linalg.pinv(np.matmul(Wdata.T, Wdata)),Wdata.T),Wlabel)\n",
        "      \n",
        "      WW = x2fx(X_train.iloc[:,Xindis[j:j+(foz)]].values)\n",
        "      imp_train_data = np.concatenate((imp_train_data, np.matmul(WW,W)),axis=1)\n",
        "      \n",
        "      TT = x2fx(X_test.iloc[:,Xindis[j:j+(foz)]].values)\n",
        "      imp_test_data = np.concatenate((imp_test_data, np.matmul(TT,W)),axis=1)\n",
        "    \n",
        "  return imp_train_data,imp_test_data\n",
        "  "
      ],
      "metadata": {
        "id": "9PpLJyDTUppd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def x2fx(x, model='quadratic'):\n",
        "    linear = np.c_[np.ones(x.shape[0]), x]\n",
        "    if model == 'linear':\n",
        "        return linear\n",
        "    if model == 'purequadratic':\n",
        "        return np.c_[linear, x**2]\n",
        "    interaction = np.array([x[:,i]*x[:,j] for i, j in comb(range(x.shape[1]), 2)]).T\n",
        "    if model == 'interaction':\n",
        "        return np.c_[linear, interaction]\n",
        "    if model == 'quadratic':\n",
        "        return np.c_[linear, interaction, x**2]\n",
        "def MajorityVoting(votes):\n",
        "  results = []\n",
        "  for i in range(0,votes.shape[1]):\n",
        "    values, counts = np.unique(votes[:,i], return_counts=True)\n",
        "    results.append(values[np.argmax(counts)])\n",
        "  return np.array(results)"
      ],
      "metadata": {
        "id": "Yrwj2I5JU8bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imp_incept_rf(X_train_features,X_valid_features,y_train):\n",
        "  imp_feature_size=1\n",
        "  foz=4\n",
        "  n_estimators=10\n",
        "  imp_tree_predicts = []\n",
        "  tree_predicts = []\n",
        "  accuracies = []\n",
        "  accuracies_imp = []  \n",
        "  X_train_features = pd.DataFrame(X_train_features)\n",
        "  X_valid_features = pd.DataFrame(X_valid_features)\n",
        "  num_class = len(np.unique(y_train))\n",
        "  d=len(X_train_features.columns)\n",
        "  imp_tr, imp_ts = generate_imp_space(X_train_features, y_train, X_valid_features, imp_feature_size, foz)\n",
        "  imp_d = imp_tr.shape[1]\n",
        "\n",
        "      #meta learner params\n",
        "  imp_sel_d = 2* round(math.log2(imp_d)) #feature\n",
        "  sel_d = 2*round(math.log2(d))\n",
        "      \n",
        "  imp_tree = RandomForestClassifier(max_features=imp_sel_d, n_estimators=10)#,random_state=42\n",
        "  imp_tree.fit(imp_tr, y_train)\n",
        "  imp_tree_predicts.append(imp_tree.predict(imp_ts))\n",
        "\n",
        "\n",
        "  tree = RandomForestClassifier(max_features=sel_d, n_estimators=10)#, random_state=42\n",
        "  tree.fit(X_train_features, y_train)\n",
        "  tree_predicts.append(tree.predict(X_valid_features))\n",
        "\n",
        "  results_imp = MajorityVoting(np.array(imp_tree_predicts))\n",
        "  results = MajorityVoting(np.array(tree_predicts))\n",
        "  return results_imp,results\n",
        "\n"
      ],
      "metadata": {
        "id": "UOWRlP6lSJfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "acc_imp=[]\n",
        "acc_norm=[]\n",
        "acc_incept=[]\n",
        "\n",
        "imp_acc=[]\n",
        "nor_acc=[]\n",
        "\n",
        "for train_index, test_index in cv.split(X,Y):\n",
        "    estimators_imp=[]\n",
        "    estimators = []\n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    Y_train = Y[train_index]\n",
        "    Y_test = Y[test_index]\n",
        "    \n",
        "    imp_feature_size=1\n",
        "    foz=4\n",
        "    n_estimators=5\n",
        "    num_class = 1\n",
        "    imp_tree_predicts = []\n",
        "    tree_predicts = []\n",
        "    base_model,modely=Inceptionv3(num_class)\n",
        "    callbacks =tf.keras.callbacks.EarlyStopping(patience=6, monitor='val_loss', verbose=1),\n",
        "      \n",
        "\n",
        "    history = modely.fit(X_train, Y_train,epochs=25,batch_size=16, validation_data=(X_test, Y_test),callbacks=[callbacks])\n",
        "    \n",
        "    pred= modely.predict(X_test)\n",
        "    predicted_class=np.argmax(pred,axis=1)\n",
        "    X_train_features,X_valid_features=incept_rf(base_model,modely,X_train,X_test,k)\n",
        "    X_train_features = pd.DataFrame(X_train_features)\n",
        "    X_valid_features = pd.DataFrame(X_valid_features)\n",
        "    d=len(X_train_features.columns)\n",
        "    imp_tree_predicts = []\n",
        "    tree_predicts = []\n",
        "    for i in range(0,n_estimators):\n",
        "        imp_tr, imp_ts = generate_imp_space(X_train_features, Y_train, X_valid_features, imp_feature_size, foz)\n",
        "        imp_d = imp_tr.shape[1]\n",
        "\n",
        "      #meta learner params\n",
        "        imp_sel_d = 2* round(math.log2(imp_d)) #feature\n",
        "        sel_d = 2*round(math.log2(d))\n",
        "      \n",
        "        imp_tree = GradientBoostingClassifier(max_features=imp_sel_d, n_estimators=50,random_state=42)#,random_state=42\n",
        "        #classifier = MultiOutputClassifier(imp_tree, n_jobs=-1)\n",
        "        estimators_imp.append(('imp_rf'+str(i), imp_tree))\n",
        "        imp_tree.fit(imp_tr, Y_train)\n",
        "        imp_tree_predicts.append(imp_tree.predict(imp_ts))\n",
        "\n",
        "\n",
        "        tree = GradientBoostingClassifier(max_features=sel_d, n_estimators=50,random_state=42)#, random_state=42\n",
        "        estimators.append(('nor_rf'+str(i), tree))\n",
        "        tree.fit(X_train_features, Y_train)\n",
        "        tree_predicts.append(tree.predict(X_valid_features))\n",
        "        \n",
        "    voting_imp = VotingClassifier(estimators=estimators_imp)\n",
        "    voting_imp.fit(imp_tr, Y_train)\n",
        "    imp_pre=voting_imp.predict(imp_ts)\n",
        "    voting_norm = VotingClassifier(estimators=estimators)\n",
        "    voting_norm.fit(X_train_features, Y_train)\n",
        "    imp_norm=voting_norm.predict(X_valid_features)\n",
        "    #result_imp = MajorityVoting(np.array(imp_tree_predicts))\n",
        "    #result_norm = MajorityVoting(np.array(tree_predicts))\n",
        "    #act=np.argmax(Y_test,axis=1)\n",
        "    imp_acc.append(metrics.accuracy_score(Y_test, imp_pre))\n",
        "    nor_acc.append(metrics.accuracy_score(Y_test, imp_norm))\n",
        "    #acc_imp.append(metrics.accuracy_score(Y_test, result_imp))\n",
        "    #acc_norm.append(metrics.accuracy_score(Y_test, result_norm))\n",
        "    acc_incept.append(metrics.accuracy_score(Y_test, predicted_class))\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "4Ec4e8Lxa8zq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}